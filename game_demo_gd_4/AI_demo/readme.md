# 游戏AI 人工智能 精讲

人工智能遵循着：感知->决策->行动

## 课程内容

- 对于常见游戏AI实现方式的设计思路讲解
- 使用godot游戏引擎实现简单、典型的的游戏AI（状态机、行为树和GOAP等）案例
- 抢先体验godot4.x版本的语法和新特性

## 决策方式

## 有限状态机（Finite-State Machines）FSM

有限状态机是目前游戏AI中最常见的行为模型。状态机的代码简单又快速，使用上强大、灵活、计算开销小。

吃饭 -> 睡觉 —> 打豆豆

进入状态、退出状态、状态的每一帧调用

目前 状态机 很少独立完成复杂AI，但在处理类似处理动画时很常用。

## 分层状态机（Hierarchical Finite-State Machines）HFSM

有限状态机虽然好，但是它有很大的缺点，当状态少的时候可以运用自如，当状态多的时候10个以上就已经结构非常复杂，而且容易出错。

分层就是对于状态的嵌套，将复杂状态用子状态方式分层。

吃饭 （吃菜、吃饭、喝水）
-> 睡觉 （入睡、深度睡眠、苏醒）
—> 打豆豆 （左勾拳、右勾拳、扫堂腿）

## 行为树（Behavior Trees）BT

不同于状态机的图状结构
行为树是树型结构的，每个节点都代表了一个行为，每个行为都可以有子行为。
所有行为都有一个先决条件，就是产生的这些行为的条件。

整个算法先从树的根部开始，然后开始检查每一个先决条件。
树的每一层只可以执行一个行为，所以当一个行为正在执行，它的兄弟节点都不会被检查，但是它们的子节点还是要检查的。
相反如果一个行为的先决条件当前并不满足，则跳过判断它的子节点，继续判断它的兄弟节点。
一个树全部检查完毕之后，决定执行优先级最大的，然后再依次执行每个动作。

行为树是无状态的，可以配合状态机使用

优势：
行为树的节点之间是不相关的，删除或增加节点，对其他节点都无影响。
所以，可扩展性也是行为树的一个优势。
另外还可以为决策树添加灵活性与随机性，父节点可以随机决定是否检查子节点。
缺点：
决策树做的选择并不一定是最优的，结果也不一定是我们想要的。
而且决策每次都要从根部往下判断选择行为节点，比状态机要耗费时间。
每次决策都要经过大量的条件判断语句，会变得非常慢。

例子：吃饭 -> 睡觉 —> 打豆豆

## 效用系统（Utility Systems）

utility-based system，基于效用的系统，会根据权重、比率、队列和许多需要考虑的事项来做出最优选择，使AI比普通的行为树更有头脑。
当需要选择新的行为时，我们通过分数（上面说的各种程度）来选择相对最优的选择，或者加上一个随机值再选择，使得接近优选的几个选择都有一定几率（几率可根据所加随机值决定）被选中。

## 目标导向型行动计划（Goal-Oriented Action  Planners）GOAP

GOAP来源于STRIPS方法，这两种都是让AI创造他们自己的方法去解决问题，
我们提供给它一系列可能的动作作为对这个世界的描述，
和每个动作使用的先决条件，和行动带来的影响。

AI拥有一个初始状态和他需要达到的目标。
有一组目标，AI可以通过优先级或当前状态选择一个。
计划系统决定一个动作序列来满足当前目标，
计划出一个像路径一样的能最简单达到目标状态的动作序列。

GOAP是一个反向链接搜索，从要实现的目标开始，
找到什么动作能实现目标，在寻找刚才动作的先决条件，
一直往前推，直到达到你的当前（初始）状态。
这种反向链接搜索替代了启发式的前向链接搜索。


## 分层任务网络（Hierarchical Task Networks） HTN

HTN也是寻找一个计划来让AI执行，不同之处在于怎样找出这个计划。

开始拥有一个初始状态和一个跟任务代表我们需要解决的问题。
原理是最高级的任务分解成更小的任务再继续分解直到我们解决问题。

每个高级任务都有很多方式被完成，当前世界状态决定高级任务要分解成哪组小任务。

HTN与GOAP相反，HTN是前向链接搜索，是从当前状态一直推到目标状态，向前推直到问题解决。

世界状态分散成几种属性，它的HP、精力，敌人的HP、相距距离，计划根据这些来制定。

我们有两种任务：原始任务和复合任务。

原始任务是可以只解决问题的任务，也就是可以直接达到目标的任务。

在游戏中，它可以为开火、装填子弹、移动到掩蔽物。

这些人物可以影响世界状态，开火这个任务需要先有子弹，并执行装填子弹这个任务。

复合任务是高级别的任务，可以看作方法。
一个方法是一组任务可以完成复合任务，这一组任务是由先决条件决定的。
复合任务让HTN推断出世界并且决定该做什么动作。

使用复合任务，我们就能构建一个HTN域，这个域是一大层任务，代表我们解决问题的方法。
